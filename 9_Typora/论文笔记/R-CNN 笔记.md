# R-CNN 笔记

**摘要：**

我们的方法结合了两个关键的因素：

1. 在候选区域上自下而上使用大型卷积神经网络(CNNs)，用以定位和分割物体。
2. 当带标签的训练数据不足时，先针对辅助任务进行有监督预训练，再进行特定任务的调优，就可以产生明显的性能提升。

​        因为我们把region proposal和CNNs结合起来，所以该方法被称为R-CNN：Regions with CNN features。

![R-CNN结构图](E:\Typora\R-CNN结构图.webp)

![R-CNN结构详解](E:\Typora\R-CNN结构详解.webp)

### 2. 用RCNN做物体检测

​        我们的物体检测系统有三个模块构成。第一个，产生类别无关的region proposal。这些推荐定义了一个候选检测区域的集合；第二个是一个大型卷积神经网络，用于从每个区域抽取特定大小的特征向量；第三个是一个指定类别的线性SVM。

#### 2.1模块设计

**区域推荐（region proposal）**
        近来有很多研究都提出了产生类别无关区域推荐的方法。比如: objectness（物体性），selective search（选择性搜索），category-independent object proposals(类别无关物体推荐)，constrained parametric min-cuts（受限参最小剪切, CPMC)，multi-scal combinatorial grouping(多尺度联合分组)，以及Ciresan等人的方法，将CNN用在规律空间块裁剪上以检测有丝分裂细胞，也算是一种特殊的区域推荐类型。由于R-CNN对特定区域算法是不关心的，所以我们采用了选择性搜索以方便和前面的工作进行可控的比较。

**特征提取（Feature extraction）**
        我们使用Krizhevsky等人所描述的CNN的一个Caffe实现版本对每个推荐区域抽取一个4096维度的特征向量把一个输入为277277大小的图片，通过五个卷积层和两个全连接层进行前向传播,最终得到一个4096-D的特征向量。读者可以参考AlexNet获得更多的网络架构细节。
        为了计算region proposal的特征，我们首先要对图像进行转换，使得它符合CNNC的输入（架构中的CNNC只能接受固定大小：277277）。这个变换有很多办法，我们使用了最简单的一种。无论候选区域是什么尺寸和宽高比，我们都把候选框变形成想要的尺寸。具体的，变形之前，我们现在候选框周围加上16的padding,再进行各向异性缩放。 这种形变使得mAp提高了3到5个百分点。在补充材料中，作者对比了各向异性和各向同性缩放缩放方法。

#### 3.2 消融研究(Ablation studies)

**没有调优的各层性能。**
        为了理解哪一层对于检测的性能十分重要，我们分析了CNN最后三层的每一层在VOC2007上面的结果。Pool5在3.1中做过剪短的表述。最后两层下面来总结一下。
　　fc6是一个与pool5连接的全连接层。为了计算特征，它和pool5的feature map（reshape成一个9216维度的向量）做了一个4096×9216的矩阵乘法，并添加了一个bias向量。中间的向量是逐个组件的半波整流（component-wise half-wave rectified）【Relu（x<- max(0,x)）】
fc7是网络的最后一层。跟fc6之间通过一个4096×4096的矩阵相乘。也是添加了bias向量和应用了ReLU。
　　我们先来看看没有调优的CNN在PASCAL上的表现，没有调优是指所有的CNN参数就是在ILSVRC2012上训练后的状态。分析每一层的性能显示**来自fc7的特征泛化能力不如fc6的特征。这意味29%的CNN参数，也就是1680万的参数可以移除掉，而且不影响mAP。更多的惊喜是即使同时移除fc6和fc7，仅仅使用pool5的特征，只使用CNN参数的6%也能有非常好的结果。可见CNN的主要表达力来自于卷积层，而不是全连接层。**这个发现提醒我们也许可以在计算一个任意尺寸的图片的稠密特征图（dense feature map）时使仅仅使用CNN的卷积层。这种表示可以直接在pool5的特征上进行滑动窗口检测的实验。

**调优后的各层性能。**
        我们来看看调优后在VOC2007上的结果表现。提升非常明显，mAP提升了8个百分点，达到了54.2%。fc6和fc7的提升明显优于pool5，**这说明pool5从ImageNet学习的特征通用性很强，在它之上层的大部分提升主要是在学习领域相关的非线性分类器。**

#### 3.4 Bounding-box回归

​        基于错误分析，我们使用了一种简单的方法减小定位误差。受到DPM[17]中使用的约束框回归训练启发，我们训练了一个线性回归模型在给定一个选择区域的pool5特征时去预测一个新的检测窗口。详细的细节参考附录C。表1、表2和图4的结果说明这个简单的方法，修复了大量的错位检测，提升了3-4个百分点。

### 5. 结论

​        最近几年，物体检测陷入停滞，表现最好的检测系统是复杂的将多低层级的图像特征与高层级的物体检测器环境与场景识别相结合。本文提出了一种简单并且可扩展的物体检测方法，达到了VOC 2012数据集相对之前最好性能的30%的提升。
​        我们取得这个性能主要通过**两个方面**：**第一是应用了自底向上的候选框训练的高容量的卷积神经网络进行定位和分割物体。**  **另外一个是使用在标签数据匮乏的情况下训练大规模神经网络的一个方法。**我们展示了在有监督的情况下使用丰富的数据集（图片分类）预训练一个网络作为辅助性的工作是很有效的，然后采用稀少数据（检测）去调优定位任务的网络。我们猜测“有监督的预训练+特定领域的调优”这一范式对于数据稀少的视觉问题是很有效的。
​        最后,我们注意到能得到这些结果，将计算机视觉中经典的工具和深度学习(自底向上的区域候选框和卷积神经网络）组合是非常重要的。而不是违背科学探索的主线，这两个部分是自然而且必然的结合。





### 回顾

* R-CNN 采用 AlexNet
* R-CNN 采用 Selective Search 技术生成 Region Proposal.
* R-CNN 在 ImageNet 上先进行预训练，然后利用成熟的权重参数在 PASCAL VOC 数据集上进行 fine-tune
* R-CNN 用 CNN 抽取特征，然后用一系列的的 SVM 做类别预测。
* R-CNN 的 bbox 位置回归基于 DPM 的灵感，自己训练了一个线性回归模型。
* R-CNN 的语义分割采用 CPMC 生成 Region
  