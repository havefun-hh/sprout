# YOLO v1 论文翻译

### 摘要

​		我们提出的YOLO是一种新的目标检测方法。以前的目标检测方法通过重新利用分类器来执行检测。与先前的方案不同，**我们将目标检测看作回归问题从空间上定位边界框（bounding box）并预测该框的类别概率**。我们**使用单个神经网络，在一次评估中直接从完整图像上预测边界框和类别概率**。由于整个检测流程仅用一个网络，所以可以直接对检测性能进行端到端的优化。

​		我们的统一架构运行是非常快的，YOLO模型的**基本版本**以**45帧/秒**的速度实时处理图像。模型的一个较小版本——**快速YOLO**，以**155帧／秒**这样惊人的速度运行，却能实现相当于其它实时检测器两倍的mAP。与最先进的检测系统相比，**YOLO虽然产生了较多的定位误差，但它几乎不会发生把背景预测为目标这样的假阳性（False Positive）的错误**。最后，**YOLO能学习到泛化性很强的目标表征**。当从自然图像学到的模型用于其它领域如艺术画作时，它的表现都优于包括DPM和R-CNN在内的其它检测方法。

### **1.** 引言

​		人们只需瞄一眼图像，立即知道图像中的物体是什么，它们在哪里以及它们如何相互作用。人类的视觉系统是快速和准确的，使得我们在无意中就能够执行复杂的任务，如驾驶。快速且准确的目标检测算法可以让计算机在没有专门传感器的情况下驾驶汽车，使辅助设备能够向人类用户传达实时的场景信息，并解锁通用响应机器人系统的潜能。

​		目前的检测系统通过重用分类器来执行检测。为了检测目标，这些系统为该目标提供一个分类器，在测试图像的不同的位置和不同的尺度上对其进行评估。像deformable parts models（DPM）这样的系统使用滑动窗口方法，其分类器在整个图像上均匀间隔的位置上运行[10]。

​		最近的方法，如R-CNN使用region proposal策略，首先在图像中生成潜在的边界框（bounding box），然后在这些框上运行分类器。在分类之后，执行用于细化边界框的后处理，消除重复的检测，并根据场景中的其它目标为边界框重新打分[13]。这些复杂的流程是很慢，很难优化的，因为每个独立的部分都必须单独进行训练。

​		我们将目标检测看作是一个单一的回归问题，直接从图像像素得到边界框坐标和类别概率。使用我们的系统——You Only Look Once（YOLO），便能得到图像上的物体是什么和物体的具体位置。

​		YOLO非常简单（见图1），它仅用单个卷积网络就能同时预测多个边界框和它们的类别概率。YOLO在整个图像上训练，并能直接优化检测性能。与传统的目标检测方法相比，这种统一的模型的一些优点如下面所列。

![YOLO v1 图1](E:\Typora\论文笔记\YOLO v1 图1.png)

**图1：YOLO检测系统。**用YOLO处理图像简单直接。我们的系统（1）将输入图像调整为448×448，（2）在图像上运行单个卷积网络，以及（3）由模型的置信度对所得到的检测进行阈值处理。

​		**第一，YOLO速度非常快。**由于我们将检测视为回归问题，所以我们不需要复杂的流程。测试时，我们在一张新图像上简单的运行我们的神经网络来预测检测结果。在Titan X GPU上不做批处理的情况下，YOLO的基础版本以每秒45帧的速度运行，而快速版本运行速度超过150fps。这意味着我们可以在不到25毫秒的延迟内实时处理流媒体视频。此外，YOLO实现了其它实时系统两倍以上的平均精度。关于我们的系统在网络摄像头上实时运行的演示，请参阅我们的项目网页：[http://pjreddie.com/yolo/](https://link.zhihu.com/?target=http%3A//pjreddie.com/yolo/)。

​		**第二，YOLO是在整个图像上进行推断的。**与基于滑动窗口和候选框的技术不同，YOLO在训练期间和测试时都会顾及到整个图像，所以它隐式地包含了关于类的上下文信息以及它们的外观。Fast R-CNN是一种很好的检测方法[14]，但由于它看不到更大的上下文，会将背景块误检为目标。与Fast R-CNN相比，YOLO的背景误检数量少了一半。

​		**第三，YOLO能学习到目标的泛化表征。**把在自然图像上进行训练的模型，用在艺术图像进行测试时，YOLO大幅优于DPM和R-CNN等顶级的检测方法。由于YOLO具有高度泛化能力，因此在应用于新领域或碰到意外的输入时不太可能出故障。

​		YOLO在精度上仍然落后于目前最先进的检测系统。虽然它可以快速识别图像中的目标，但它在定位某些物体尤其是小的物体上精度不高。我们在实验中会进一步探讨精度／时间的权衡。我们所有的训练和测试代码都是开源的，而且各种预训练模型也都可以下载。

### **2.** 统一检测

​		我们将目标检测的独立部分整合到单个神经网络中。我们的网络使用整个图像的特征来预测每个边界框。它还可以同时预测一张图像中的所有类别的所有边界框。这意味着我们的网络对整张图像和图像中的所有目标进行推断。YOLO设计可实现端到端训练和实时的速度，同时保持较高的平均精度。

​		我们的系统将输入图像分成S×S的网格。如果目标的中心落入某个网格单元中，那么该网格单元就负责检测该目标。

​		

![YOLO v1 图2](E:\Typora\论文笔记\YOLO v1 图2.png)

**图2： 模型**。我们的系统检测模型作为一个回归问题。它将每张图片分成 $S \times S$ 个网格，对于每个网格单元预测 $B$ 个边界框、边界框的置信度及 $C$ 个类别可能性。这些预测被编码成一个 $S \times S \times (B*5+C)$ 的张量。

​		每个网格单元都会预测B个边界框和这些框的置信度分数（confidence scores）。这些置信度分数反映了该模型对那个框内是否包含目标的信心，以及它对自己的预测的准确度的估量。在形式上，我们将置信度定义为 $Pr(Object)*IOU^{truth}_{pred}$ 。如果该单元格中不存在目标，则置信度分数应为零。否则，我们希望置信度分数等于预测框（predict box）与真实标签框（ground truth）之间联合部分的交集（IOU）。

​		每个边界框包含5个预测：$x, y, w, h$和置信度。(*x*，*y*)坐标表示边界框的中心相对于网格单元的边界的值，而宽度和高度则是相对于整张图像来预测的。置信度预测表示预测框与任意实际边界框之间的IOU。

​		每个网格单元还预测$C$个条件类别概率 $Pr(Class_i|Object)$，这些概率以包含目标的网格单元为条件。不管边界框的的数量 $B$ 是多少，每个网格单元我们只预测一组类别概率。

​		在测试时，我们把条件类概率和每个框的预测的置信度值相乘，
$$
Pr(Class_i|Object)*Pr(Object)*IOU^{truth}_{pred}=Pr(Class_i)*IOU^{truth}_{pred} \qquad(1)
$$
​		它给出了每个框特定类别的置信度分数。这些分数体现了该类出现在框中的概率以及预测框拟合目标的程度。

​		为了在Pascal VOC上评估YOLO，我们使用 $S=7$，$B=2$。Pascal VOC有20个标注类，所以 $C=20$。我们最终的预测是 $7×7×30$ 的张量。

#### 2.1. 网络设计

​		我们将此模型作为卷积神经网络来实现，并在Pascal VOC检测数据集[9]上进行评估。网络的初始卷积层从图像中提取特征，而全连接层负责预测输出概率和坐标。

​		我们的网络架构受图像分类模型GoogLeNet的启发[34]。我们的网络有24个卷积层，后面是2个全连接层。我们只使用1×1降维层，后面是3×3卷积层，这与Lin等人[22]类似，而不是GoogLeNet使用的Inception模块。完整的网络如图3所示。

![YOLO v1 图3](E:\Typora\论文笔记\YOLO v1 图3.png)

**图3 架构。** 我们的检测网络有24个卷积层，跟着是2个全连接的层。交替的1×1卷积层减少了来自前面层的特征空间。我们在分辨率的一半（224×224输入图像）上预训练ImageNet分类任务上的卷积层，然后将分辨率加倍以进行检测训练。		

​		我们还训练了快速版本的YOLO，旨在推动快速目标检测的界限。快速YOLO使用具有较少卷积层（9层而不是24层）的神经网络，在这些层中使用较少的滤波器。除了网络规模之外，基本版YOLO和快速YOLO的所有训练和测试参数都是相同的。我们网络的最终输出是 $7×7×30$ 的预测张量。

#### 2.2 训练

​		我们在ImageNet的1000类竞赛数据集[30]上预训练我们的卷积层。对于预训练，我们使用图3中的前20个卷积层，接着是平均池化层和全连接层。我们对这个网络进行了大约一周的训练，并且在ImageNet 2012验证集上获得了单一裁剪图像88%的top-5准确率，与Caffe模型池中的GoogLeNet模型相当。我们使用Darknet框架进行所有的训练和推断[26]。

​		然后我们转换模型来执行检测训练。Ren等人表明，预训练网络中增加卷积层和连接层可以提高性能[29]。按照他们的方法，我们添加了四个卷积层和两个全连接层，这些层的权重都用随机值初始化。检测通常需要细粒度的视觉信息，因此我们将网络的输入分辨率从224×224改为448×448。

​		模型的最后一层预测类概率和边界框坐标。我们通过图像宽度和高度来规范边界框的宽度和高度，使它们落在0和1之间。我们将边界框x和y坐标参数化为特定网格单元位置的偏移量，所以它们的值被限定在在0和1之间。

​		模型的最后一层使用线性激活函数，而所有其它的层使用下面的leaky rectified activation：
$$
\phi(x)=\begin{cases}
x&,if \ x > 0\\
0.1x&, otherwise&\\
\end{cases}
$$
​		我们对模型输出的平方和误差进行优化。我们选择使用平方和误差，是因为它易于优化，但是它并不完全符合最大化平均精度（average precision）的目标。它给分类误差与定位误差的权重是一样的，这点可能并不理想。另外，每个图像都有很多网格单元并没有包含任何目标，这将这些单元格的“置信度”分数推向零，通常压制了包含目标的单元格的梯度。这可能导致模型不稳定，从而导致训练在早期就发散。

​		**为了弥补平方和误差的缺陷，我们增加了边界框坐标预测的损失，并减少了不包含目标的框的置信度预测的损失**。 我们使用两个参数 $λ_{coord}$ 和 $λ_{noobj}$ 来实现这一点。 我们设定$λ_{coord}=5$ 和 $λ_{noobj}=.5$。

​		平方和误差对大框和小框的误差权衡是一样的，而**我们的错误指标应该要体现出，大框的小偏差的重要性不如小框的小偏差的重要性**。为了部分解决这个问题，**我们直接预测边界框宽度和高度的平方根，而不是宽度和高度**。

​		YOLO为每个网格单元预测多个边界框。在训练时，每个目标我们只需要一个边界框预测器来负责。若某预测器的预测值与目标的实际值的IOU值最高，则这个预测器被指定为“负责”预测该目标。**这导致边界框预测器的专业化**。**每个预测器可以更好地预测特定大小，方向角，或目标的类别，从而改善整体召回率**。

​		在训练期间，我们优化以下多部分损失函数：
$$
λ_{coord}\sum_{i=0}^{S^2}\sum_{j=0}^{B}\texttt{1}_{ij}^{obj}[(x_i-\hat{x_i})^2+(y_i-\hat{y_i})^2]+\\
λ_{coord}\sum_{i=0}^{S^2}\sum_{j=0}^{B}\texttt{1}_{ij}^{obj}[(\sqrt{w_i}-\sqrt{\hat{w_i}})^2+(\sqrt{h_i}-\sqrt{\hat{h_i}})^2]+\\
\sum_{i=0}^{S^2}\sum_{j=0}^{B}\texttt{1}_{ij}^{obj}(C_i-\hat{C_i})^2+\\
λ_{coord}\sum_{i=0}^{S^2}\texttt{1}_{ij}^{obj}\sum_{c\in classes}(p_i(c)-\hat{p_i}(c))^2
$$
​		其中 $\texttt{1}_{ij}^{obj}$ 表示目标是否出现在网格单元 $i$ 中, $\texttt{1}_{ij}^{obj}$ 表示单元格 $i$ 中的第 $j$ 个边界框预测器“负责”该预测。注意，如果目标存在于该网格单元中（前面讨论的条件类别概率），则损失函数仅惩罚分类错误。如果预测器“负责”实际边界框（即该网格单元中具有最高IOU的预测器），则它也仅惩罚边界框坐标错误。

​		我们用Pascal VOC 2007和2012的训练集和验证数据集进行了大约135个迭代的网络训练。因为我们仅在Pascal VOC 2012上进行测试，所以我们的训练集里包含了Pascal VOC 2007的测试数据。在整个训练过程中，我们使用的批量大小是64，动量为0.9，衰减率是0.0005。

​		**我们的学习率计划如下**：在第一个迭代周期，我们将学习率从 $10^{-3}$ 慢慢地提高到 $10^{-2}$。如果从大的学习率开始训练，我们的模型通常会由于不稳定的梯度而发散。我们继续以  $10^{-2}$ 进行75个周期的训练，然后以 $10^{-3}$ 进行30个周期的训练，最后以 $10^{-4}$ 进行30个周期的训练。

​		**为避免过拟合，我们使用了Dropout和大量的数据增强**。 在第一个连接层之后的dropout层的丢弃率设置为0.5，以防止层之间的相互适应[18]。 对于数据增强，我们引入高达20％的原始图像大小的随机缩放和平移。我们还在HSV色彩空间中以高达1.5的因子随机调整图像的曝光度和饱和度。

#### 2.3. 推断

​		就像在训练中一样，预测测试图像的检测只需要一次网络评估。在Pascal VOC上，每张图像上网络预测98个边界框和每个框的类别概率。YOLO在测试时非常快，因为它只需要一次网络评估，这与基于分类器的方法不同。

​		**网格设计强化了边界框预测中的空间多样性**。通常一个目标落在哪一个网格单元中是很明显的，而网络只能为每个目标预测一个边界框。然而，一些大的目标或接近多个网格单元的边界的目标能被多个网格单元定位。**非极大值抑制可以用来修正这些多重检测。非最大抑制对于YOLO的性能的影响不像对于R-CNN或DPM那样重要，但也能增加2−3%的mAP**。

#### 2.4. YOLO的限制

​		YOLO给边界框预测强加空间约束，因为每个网格单元只预测两个框和只能有一个类别。这个空间约束限制了我们的模型可以预测的邻近目标的数量。**我们的模型难以预测群组中出现的小物体（比如鸟群）**。

​		由于我们的模型学习是从数据中预测边界框，因此它**很难泛化到新的、不常见的长宽比或配置的目标**。我们的模型也使用相对较粗糙的特征来预测边界框，因为输入图像在我们的架构中历经了多个下采样层。

​		最后，我们的训练基于一个逼近检测性能的损失函数，这个损失函数无差别地处理小边界框与大边界框的误差。大边界框的小误差通常是无关要紧的，但小边界框的小误差对IOU的影响要大得多。我们的主要错误来自于不正确的定位。

### **3.** 与其它检测系统的比较

​		目标检测是计算机视觉中的核心问题。检测流程通常是首先从输入图像上提取一组鲁棒特征（Haar [25]，SIFT [23]，HOG [4]，卷积特征[6]）。然后，分类器[36,21,13,10]或定位器[1,32]被用来识别特征空间中的目标。这些分类器或定位器或在整个图像上或在图像中的一些子区域上以滑动窗口的方式运行[35,15,39]。我们将YOLO检测系统与几种顶级检测框架进行比较，突出了关键的相似性和差异性。

**Deformable parts models**。可变形部分模型（DPM）使用滑动窗口方法进行目标检测[10]。DPM使用不相交的流程来提取静态特征，对区域进行分类，预测高评分区域的边界框等。我们的系统用一个卷积神经网络替换所有这些不同的部分。网络同时进行特征提取，边界框预测，非极大值抑制和上下文推理。网络的特征是在在线训练出来的而不是静态，因此可以根据特定的检测任务进行优化。我们的统一架构比DPM更快，更准确。

**R-CNN**。R-CNN及其变体使用区域提议而不是滑动窗口来查找图像中的目标。选择性搜索[35]生成潜在的边界框，卷积网络提取特征，SVM对框进行评分，线性模型调整边界框，非最大抑制消除重复检测。 这个复杂流水线的每个阶段都必须独立地进行精确调整，所得到的系统非常缓慢，在测试时间每个图像需要超过40秒[14]。

YOLO与R-CNN有一些相似之处。每个网格单元提出潜在的边界框并使用卷积特征对这些框进行评分。然而，我们的系统对网格单元的候选框施加空间限制，这有助于缓解对同一目标的多次检测的问题。 我们的系统还生成了更少的边界框，每张图像只有98个，而选择性搜索则有约2000个。最后，我们的系统将这些单独的组件组合成一个单一的，共同优化的模型

**其它快速检测器**。 Fast 和 Faster R-CNN 通过共享计算和使用神经网络替代选择性搜索[14]，[28]来提出候选区域来加速R-CNN框架。虽然它们提供了比R-CNN更快的速度和更高的准确度，但仍然不能达到实时性能。

​		许多研究工作集中在加快DPM流程上[31] [38] [5]。它们加速HOG计算，使用级联，并将计算推动到GPU上。但是，实际上只有30Hz的DPM [31]可以实时运行。

​		YOLO并没有试图优化大型检测流程的各个部分，相反，它被设计为快速检测，完全抛弃该流程。

​		像人脸或行人等单个类别的检测器可以高度优化，因为他们只需处理较少的多样性[37]。YOLO是一种通用的检测器，它可以同时检测多个目标。

**Deep MultiBox**。 与R-CNN不同，Szegedy等人训练一个卷积神经网络来预测感兴趣的区域[8]，而不是使用选择性搜索。 MultiBox还可以通过用单个类别预测替换置信度预测来执行单个目标检测。 但是，MultiBox无法执行一般的目标检测，并且仍然只是较大检测流水线中的一部分，需要进一步的图像补丁分类。 YOLO和MultiBox都使用卷积网络来预测图像中的边界框，但YOLO是一个完整的检测系统。

**OverFeat**。Sermanet等人训练了一个卷积神经网络来执行定位，并使该定位器进行检测[32]。OverFeat高效地执行滑动窗口检测，但它仍然是一个不相交的系统。OverFeat优化了定位功能，而不是检测性能。像DPM一样，定位器在进行预测时只能看到局部信息。OverFeat无法推断全局上下文，因此需要大量的后处理来产生连贯的检测。

**MultiGrasp**。 我们的系统在设计上类似于Redmon等[27]的抓取检测。 我们的网格边界框预测方法基于MultiGrasp系统进行回归分析。 然而，抓取检测比物体检测要简单得多。 MultiGrasp只需要为包含一个目标的图像预测一个可抓取区域。 它不必估计目标的大小，位置或边界或预测它的类别，只需找到适合抓取的区域就可以了。 而YOLO则是预测图像中多个类的多个目标的边界框和类概率。

### 4. 实验

​		首先，我们在PASCAL VOC 2007上比较YOLO和其它的实时检测系统。为了弄清YOLO和R-CNN变体之间的差异，我们研究了YOLO和R-CNN性能最高的版本之一Fast R-CNN[14]在VOC 2007上错误率。根据不同的误差曲线，我们显示YOLO可以用来重新评估Fast R-CNN检测，并减少背景假阳性带来的错误，从而显著提升性能。我们还展示了在VOC 2012上的结果，并与目前最先进的方法比较了mAP。最后，在两个艺术图像数据集上我们显示了YOLO可以比其它检测器更好地泛化到新的领域。

#### 4.1 与其它实时系统的比较

​		目标检测方面的许多研究工作都集中在快速制作标准的检测流程上[5]，[38]，[31]，[14]，[17]，[28]。然而，只有Sadeghi等人实际上产生了一个实时运行的检测系统（每秒30帧或更好）[31]。我们将YOLO与DPM的GPU实现进行了比较，其在30Hz或100Hz下运行。虽然其它的算法没有达到实时性的标准，我们也比较了它们的mAP和速度的关系，从而探讨目标检测系统中精度和性能之间的权衡。

​		快速YOLO是PASCAL上最快的目标检测方法；据我们所知，它是现有的最快的目标检测器。具有52.7%的mAP，实时检测的精度是以前的方法的两倍以上。普通版YOLO将mAP推到63.4%的同时保持了实时性能。

![YOLO v1 表1](E:\Typora\论文笔记\YOLO v1 表1.png)

**表1：PASCAL VOC 2007上的实时系统**。比较快速检测器的性能和速度。 快速的YOLO是PASCAL VOC检测记录中速度最快的检测器，并且仍然是其他任何实时检测器的两倍。 YOLO比快速版本更精确10 mAP，同时仍高于实时速度

​		我们还使用VGG-16训练YOLO。 这个模型比普通版YOLO更精确，但也更慢。 它的作用是与依赖于VGG-16的其他检测系统进行比较，但由于它比实时更慢，所以本文的其他部分将重点放在我们更快的模型上。

​		最快的DPM可以在不牺牲太多mAP的情况下有效加速DPM，但仍然会将实时性能降低2倍[38]。与神经网络方法相比，DPM的检测精度相对较低，这也是限制它的原因。

​		Fast R-CNN加快了R-CNN的分类阶段，但它仍然依赖于选择性搜索，每个图像需要大约2秒才能生成边界框提议。因此，它虽然具有较高的mAP，但的速度是0.5 fps，仍然远未达到实时。

​		最近的Faster R-CNN用神经网络替代了选择性搜索来候选边界框，类似于Szegedy等人[8]的方法。在我们的测试中，他们最准确的模型达到了7fps，而较小的，不太准确的模型以18 fps运行。 Faster R-CNN的VGG-16版本比YOLO高出10mAP，但比YOLO慢了6倍。 Zeiler-Fergus 版本的Faster R-CNN只比YOLO慢2.5倍，但也不如YOLO准确。

#### 4.2. VOC 2007的错误分析

​		为了进一步研究YOLO和最先进的检测器之间的差异，我们详细分析了VOC 2007的结果。我们将YOLO与Fast R-CNN进行比较，因为Fast R-CNN是PASCAL上性能最高的检测器之一并且它的检测代码是可公开得到的。

​		我们使用Hoiem等人的方法和工具[19]，对于测试的每个类别，我们查看该类别的前N个预测。每个预测都或是正确的，或是根据错误的类型进行分类：

*  Correct：类别正确，IOU>0.5

* Localization：类别正确，0.1<*IOU*<0.5

* Similar：类别相似，IOU >0.1

* Other：类别错误，IOU >0.1

* Background：任何IOU <0.1的目标。

  ​	图4显示了在所有20个类别上每种错误类型的平均值的分解图。

![YOLO v1 图4](E:\Typora\论文笔记\YOLO v1 图4.png)

**图4：错误分析**：快速R-CNN与YOLO这些图表显示了各种类别（N =该类别中目标的个数）的前N个检测中的本地化和背景错误的百分比。

​		YOLO难以正确地定位目标，因此定位错误比YOLO的所有错误都要多。Fast R-CNN定位错误更少，但把背景误认成目标的错误比较多。它的最高检测结果中有13.6％是是不包含任何目标的误报。 Fast R-CNN把背景误认成目标的概率比YOLO高出3倍。

#### 4.3. 结合Fast R-CNN 和 YOLO

​		YOLO误认背景为目标的情况比Fast R-CNN少得多。 通过使用YOLO消除Fast R-CNN的背景检测，我们获得了显着的性能提升。 对于R-CNN预测的每个边界框，我们检查YOLO是否预测了一个类似的框。 如果确实如此，那么我们会根据YOLO预测的概率和两个框之间的重叠情况提高预测值。

​		最好的Fast R-CNN模型在VOC 2007测试集中达到了71.8％的mAP。 当与YOLO合并时，其mAP增加了3.2％至75.0％。 我们还尝试将顶级Fast R-CNN模型与其他几个版本的Fast R-CNN结合起来。 这时的结合的平均增长率在0.3％至0.6％之间，详见表2。



![YOLO v1 表2](E:\Typora\论文笔记\YOLO v1 表2.png)

表2：VOC 2007的模型组合实验。我们研究了将各种模型与Fast R-CNN的最佳版本结合的效果。 Fast R-CNN的其他版本只提供很小的好处，而YOLO提供显着的性能提升。

​		结合YOLO后获得的性能提高不仅仅是模型整合的副产品，因为结合不同版本的Fast R-CNN几乎没有什么益处。 相反，正是因为YOLO在测试时间出现了各种各样的错误，所以它在提高Fast R-CNN的性能方面非常有效。

​		不幸的是，这种组合不会从YOLO的速度中受益，因为我们分别运行每个模型，然后合并结果。 但是，由于YOLO速度如此之快，与Fast R-CNN相比，它不会增加任何显着的计算时间。

#### 4.4. VOC 2012的结果

​		在VOC 2012测试集中，YOLO的得分是57.9％mAp。这比现有最先进的技术水平低，更接近使用VGG-16的原始的R-CNN，见表3.与其最接近的竞争对手相比，我们的系统在小物体上表现不理想。 在瓶子，羊，电视/监视器等类别上，YOLO得分比R-CNN和Feature Edit低8-10％。 然而，在其他类别，如猫和火车YOLO实现更高的性能。

​		我们的Fast R-CNN + YOLO模型组合是性能最高的检测方法之一。 Fast R-CNN与YOLO的组合提高了2.3％，在公共排行榜上提升了5个位置。

![YOLO v1 表3](E:\Typora\论文笔记\YOLO v1 表3.png)

表3：PASCAL VOC 2012排行榜。YOLO与截至2015年11月6日的完整comp4（允许外部数据）公共排行榜进行比较。显示了各种检测方法的平均精度和每类平均精度。 YOLO是唯一的实时检测器。 Fast R-CNN + YOLO是第四高评分方法，比Fast R-CNN提升了2.3％。

#### 4.5. 泛化性：艺术图像的人物检测

​		用于目标检测的学术数据集的训练和测试数据是服从同一分布的。但在现实世界的应用中，很难预测所有可能的用例，他的测试数据可能与系统已经看到的不同[3]。我们将YOLO与其他检测系统在毕加索数据集[12]和人物艺术数据集[3]上进行了比较，这两个数据集用于检测艺术图像检测人形。

​		图5显示了YOLO和其他检测方法之间的性能比较。作为参考，我们在上提供VOC 2007的人形检测的AP，其中所有模型仅在VOC 2007数据上训练。在Picasso数据集上测试的模型在是在VOC 2012上训练，而People-Art数据集上的模型则在VOC 2010上训练。

![YOLO v1 图5](E:\Typora\论文笔记\YOLO v1 图5.png)

图5：Picasso和People-Art数据库上的泛化结果

​		R-CNN在VOC 2007上有很高的AP值。然而，当应用于艺术图像时，R-CNN显着下降。 R-CNN使用选择性搜索来调整自然图像的候选边界框。 R-CNN在分类器阶段只能看到小区域，而且需要有很好的候选框。

​		DPM在应用于艺术图像时可以很好地保持其AP。之前的研究认为DPM表现良好，因为它具有强大的物体形状和布局空间模型。虽然DPM不会像R-CNN那样退化，但它的AP本来就很低。

​		YOLO在VOC 2007上表现出色，其应用于艺术图像时其AP降低程度低于其他方法。与DPM一样，YOLO模拟目标的大小和形状，以及目标之间的关系和目标通常出现的位置之间的关系。艺术图像和自然图像在像素级别上有很大不同，但它们在物体的大小和形状方面相似，因此YOLO仍然可以预测好的边界框和检测结果。

### 5.现实实时检测

​		YOLO是一款快速，精确的物体检测器，非常适合计算机视觉应用。 我们将YOLO连接到网络摄像头，并验证它是否保持实时性能，包括从摄像头获取图像并显示检测结果的时间。

​		由此产生的系统是互动的和参与的。 虽然YOLO单独处理图像，但当连接到网络摄像头时，它的功能类似于跟踪系统，可在目标移动并在外观上发生变化时检测目标。 系统演示和源代码可在我们的项目网站上找到：[http://pjreddie.com/yolo/](https://link.zhihu.com/?target=http%3A//pjreddie.com/yolo/)。

![YOLO v1 图6](E:\Typora\论文笔记\YOLO v1 图6.png)

图6：YOLO在检测线上的艺术品图片和自然图片的表现。虽然它将一个人识别成飞机但是准确性还是很高的。

### 6. 结论

​		我们介绍YOLO——一种用于物体检测的统一模型。 我们的模型构造简单，可以直接在完整图像上训练。 与基于分类器的方法不同，YOLO是通过与检测性能直接对应的损失函数进行训练的，并且整个模型是一起训练的。

​		快速YOLO是文献中最快的通用目标检测器，YOLO推动实时对象检测的最新技术。 YOLO还能很好地推广到新领域，使其成为快速，鲁棒性强的应用的理想选择。